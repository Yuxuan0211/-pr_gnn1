# src/trainer.py
import torch
from torch.optim import Adam
try:
    from torch.optim.lr_scheduler import ReduceLROnPlateau
except ImportError:
    print("âš ï¸  æ— æ³•å¯¼å…¥ReduceLROnPlateauï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆå®ç°")
    class ReduceLROnPlateau:
        def __init__(self, optimizer, mode='min', factor=0.1, patience=10, 
                    min_lr=0, verbose=False):
            self.optimizer = optimizer
            self.mode = mode
            self.factor = factor
            self.patience = patience
            self.min_lr = min_lr
            self.verbose = verbose
            self.best = float('inf') if mode == 'min' else -float('inf')
            self.num_bad_epochs = 0
            
        def step(self, metrics):
            if self.mode == 'min':
                is_better = metrics < self.best
            else:
                is_better = metrics > self.best
                
            if is_better:
                self.best = metrics
                self.num_bad_epochs = 0
            else:
                self.num_bad_epochs += 1
                
            if self.num_bad_epochs >= self.patience:
                self._reduce_lr()
                self.num_bad_epochs = 0
                
        def _reduce_lr(self):
            for param_group in self.optimizer.param_groups:
                old_lr = param_group['lr']
                new_lr = max(old_lr * self.factor, self.min_lr)
                if old_lr - new_lr > 1e-8:
                    param_group['lr'] = new_lr
                    if self.verbose:
                        print(f'å°†å­¦ä¹ ç‡ä» {old_lr:.2e} é™ä½åˆ° {new_lr:.2e}')

from tqdm import tqdm
import os
import sys
import numpy as np
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)

from pr_gnn.src.physics_loss import PhysicsLoss
from pr_gnn.src.assign_regions import get_regional_masks

class SimpleData(torch.Tensor):
    def __new__(cls, y, pos=None):
        # ä½¿ç”¨yä½œä¸ºåŸºç¡€å¼ é‡
        instance = super().__new__(cls, y)
        instance.pos = pos
        return instance
    
    def __init__(self, y, pos=None):
        super().__init__()
        # ç¡®ä¿yæ˜¯å¼ é‡
        if not isinstance(y, torch.Tensor):
            self.data = torch.as_tensor(y)
        else:
            self.data = y
        self.pos = pos
    
    def size(self, *args, **kwargs):
        return self.data.size(*args, **kwargs)

class PRGNNTrainer:
    def __init__(self, model, config):
        self.model = model
        self.config = config
        self.device = config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        # ä¼˜åŒ–å™¨åˆå§‹åŒ–
        self.optimizer = Adam(
            model.parameters(),
            lr=config.get('lr', 0.001),
            weight_decay=config.get('weight_decay', 1e-5)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=config.get('lr_factor', 0.5),
            patience=config.get('lr_patience', 10),
            min_lr=config.get('min_lr', 1e-6),
            verbose=True
        )
        
        # ç‰©ç†æŸå¤±è®¡ç®—å™¨
        self.physics_loss = PhysicsLoss(config)
        
        # è®­ç»ƒçŠ¶æ€è®°å½•
        self.train_state = {
            'train_loss_history': [],
            'val_loss_history': [],
            'best_val_loss': float('inf'),
            'best_epoch': 0,
            'converge_count': 0,
            'current_epoch': 0,
            'lr_history': []
        }
        
        # åŒºåŸŸæ©ç ç¼“å­˜
        self.region_mask_cache = None

    def _get_region_mask(self, data) -> torch.Tensor:
        """è·å–åŒºåŸŸæ©ç ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰"""
        if self.region_mask_cache is None or len(self.region_mask_cache) != len(data.y):
            masks = get_regional_masks(data.y)
            region_mask = torch.zeros(len(data.y), dtype=torch.long, device=self.device)
            region_mask[masks["shock"]] = 0
            region_mask[masks["boundary"]] = 1
            region_mask[masks["wake"]] = 2
            region_mask[masks["inviscid"]] = 3
            region_mask[masks["freestream"]] = 4
            self.region_mask_cache = region_mask
        return self.region_mask_cache

    def regional_pretrain(self, data, val_data=None):
        data = data.to(self.device)
        if val_data is not None:
            val_data = val_data.to(self.device)
        
        self.model.train()
        region_mask = self._get_region_mask(data)

        # æ ¹æ®èŠ‚ç‚¹æ•°åŠ¨æ€è°ƒæ•´è®­ç»ƒè½®æ•°
        total_nodes = len(data.y)
        base_epochs = self.config.get('pre_epochs', 100)
        scale_factor = min(1.0, 10000 / total_nodes)
        adjusted_epochs = max(10, int(base_epochs * scale_factor))
        print(f"ğŸ“Š åŒºåŸŸé¢„è®­ç»ƒé…ç½®ï¼šæ€»èŠ‚ç‚¹æ•°{total_nodes}ï¼Œè°ƒæ•´åè½®æ•°{adjusted_epochs}")

        # æŒ‰åŒºåŸŸè¿›è¡Œé¢„è®­ç»ƒ
        for region_id in range(5):
            print(f"\n=== é¢„è®­ç»ƒé˜¶æ®µ: åŒºåŸŸ {region_id} ===")
            region_mask_bool = (region_mask == region_id)
            
            # è·³è¿‡æ— èŠ‚ç‚¹çš„åŒºåŸŸ
            if not region_mask_bool.any():
                print(f"âš ï¸  åŒºåŸŸ {region_id} æ— èŠ‚ç‚¹ï¼Œè·³è¿‡è¯¥åŒºåŸŸ")
                continue
            
            # é‡ç½®è¯¥åŒºåŸŸçš„æ”¶æ•›è®¡æ•°å™¨
            self.train_state['converge_count'] = 0
            
            for epoch in range(adjusted_epochs):
                self.train_state['current_epoch'] += 1
                current_lr = self.optimizer.param_groups[0]['lr']
                self.train_state['lr_history'].append(current_lr)

                # è®­ç»ƒæ­¥éª¤
                self.optimizer.zero_grad()
                pred, _ = self.model(data.x, data.edge_index)
                # å°†å¸ƒå°”æ©ç è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•
                region_indices = torch.where(region_mask_bool)[0]
                
                # å¤„ç†posæ•°æ®
                pos = None
                if hasattr(data, 'pos') and data.pos is not None:
                    pos = data.pos[region_indices]
                
                # ç›´æ¥ä¼ é€’yå¼ é‡è€Œä¸æ˜¯å°è£…å¯¹è±¡
                temp_data = SimpleData(
                    y=data.y[region_indices],
                    pos=pos
                )
                
                total_loss, loss_dict = self.physics_loss(
                    pred[region_indices],
                    temp_data,
                    region_mask[region_indices]
                )
                total_loss.backward()
                self.optimizer.step()

                # è®°å½•è®­ç»ƒæŸå¤±
                self.train_state['train_loss_history'].append(total_loss.item())

                # éªŒè¯é›†è¯„ä¼°ï¼ˆå¦‚æœæœ‰ï¼‰
                val_loss_dict = {}
                if val_data is not None:
                    val_loss_dict = self._evaluate(val_data)
                    self.train_state['val_loss_history'].append(val_loss_dict['val_total_loss'])
                    # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                    self.scheduler.step(val_loss_dict['val_total_loss'])

                # æ‰“å°æ—¥å¿—ï¼ˆæ¯5ä¸ªepochï¼‰
                if epoch % 5 == 0:
                    log_msg = (f"åŒºåŸŸ {region_id} | Epoch {epoch:3d}/{adjusted_epochs} | LR: {current_lr:.6f} | "
                               f"Train Loss: {total_loss.item():.6f} | "
                               f"Sup Loss: {loss_dict['L_supervised']:.6f}")
                    if val_data is not None:
                        log_msg += f" | Val Loss: {val_loss_dict['val_total_loss']:.6f}"
                    print(log_msg)

                # æ”¶æ•›æ£€éªŒï¼ˆå¦‚æœæœ‰éªŒè¯é›†ï¼‰
                if val_data is not None:
                    is_converged, converge_msg = self._check_convergence()
                    print(f"ğŸ” æ”¶æ•›çŠ¶æ€: {converge_msg}")
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    if self.train_state['current_epoch'] == self.train_state['best_epoch']:
                        self.save_model(f"models/best_pretrain_region_{region_id}.pth")
                    
                    # å¦‚æœæ”¶æ•›ï¼Œæå‰åœæ­¢è¯¥åŒºåŸŸè®­ç»ƒ
                    if is_converged:
                        print(f"ğŸ‰ åŒºåŸŸ {region_id} é¢„è®­ç»ƒæå‰æ”¶æ•›ï¼Œåœæ­¢è®­ç»ƒ")
                        break

            print(f"=== åŒºåŸŸ {region_id} é¢„è®­ç»ƒå®Œæˆ ===")

        # è¿”å›è®­ç»ƒå†å²
        return {
            'train_loss': self.train_state['train_loss_history'],
            'val_loss': self.train_state['val_loss_history'],
            'lr_history': self.train_state['lr_history']
        }

    def global_finetune(self, data, epochs, val_data=None):
        data = data.to(self.device)
        if val_data is not None:
            val_data = val_data.to(self.device)
        
        self.model.train()
        region_mask = self._get_region_mask(data)
        total_nodes = len(data.y)
        
        # åŠ¨æ€è°ƒæ•´batch size
        if total_nodes > 10000:
            batch_size = 1024
        elif total_nodes > 5000:
            batch_size = 512
        else:
            batch_size = 256
        print(f"ğŸ“Š å…¨å±€å¾®è°ƒé…ç½®ï¼šæ€»èŠ‚ç‚¹æ•°{total_nodes}ï¼Œbatch size{batch_size}ï¼Œæœ€å¤§è½®æ•°{epochs}")

        # æ¢¯åº¦ç´¯ç§¯å‚æ•°
        grad_accum_steps = self.config.get('grad_accum_steps', 1)
        if grad_accum_steps > 1:
            print(f"âš ï¸  å¯ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œç´¯ç§¯æ­¥æ•°ï¼š{grad_accum_steps}")

        # å¾®è°ƒè®­ç»ƒå¾ªç¯
        for epoch in tqdm(range(epochs), desc="å…¨å±€å¾®è°ƒ"):
            self.train_state['current_epoch'] += 1
            current_lr = self.optimizer.param_groups[0]['lr']
            self.train_state['lr_history'].append(current_lr)
            
            total_train_loss = 0.0
            batch_count = 0

            # åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†
            for i in range(0, total_nodes, batch_size):
                # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æ©ç 
                batch_end = min(i + batch_size, total_nodes)
                batch_mask = slice(i, batch_end)
                
                # æ‰¹æ¬¡è®­ç»ƒï¼ˆæ¢¯åº¦ç´¯ç§¯ï¼‰
                self.optimizer.zero_grad() if batch_count % grad_accum_steps == 0 else None
                
                pred, _ = self.model(data.x, data.edge_index)
                # åªè®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±
                # å¤„ç†posæ•°æ®
                pos = None
                if hasattr(data, 'pos') and data.pos is not None:
                    pos = data.pos[batch_mask]
                
                temp_data = SimpleData(
                    y=data.y[batch_mask],
                    pos=pos
                )
                
                batch_loss, _ = self.physics_loss(
                    pred[batch_mask],
                    temp_data,
                    region_mask[batch_mask]
                )
                
                # æ¢¯åº¦ç´¯ç§¯ï¼šæŸå¤±é™¤ä»¥ç´¯ç§¯æ­¥æ•°
                batch_loss = batch_loss / grad_accum_steps
                batch_loss.backward()
                
                total_train_loss += batch_loss.item() * grad_accum_steps
                batch_count += 1

                # ç´¯ç§¯åˆ°æŒ‡å®šæ­¥æ•°åæ›´æ–°å‚æ•°
                if batch_count % grad_accum_steps == 0 or batch_count == (total_nodes // batch_size + 1):
                    self.optimizer.step()

            # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
            avg_train_loss = total_train_loss / batch_count
            self.train_state['train_loss_history'].append(avg_train_loss)

            # éªŒè¯é›†è¯„ä¼°ï¼ˆå¦‚æœæœ‰ï¼‰
            val_loss_dict = {}
            if val_data is not None:
                val_loss_dict = self._evaluate(val_data)
                self.train_state['val_loss_history'].append(val_loss_dict['val_total_loss'])
                # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                self.scheduler.step(val_loss_dict['val_total_loss'])

            # æ‰“å°æ—¥å¿—ï¼ˆæ¯10ä¸ªepochï¼‰
            if epoch % 10 == 0:
                log_msg = (f"å¾®è°ƒ Epoch {epoch:3d}/{epochs} | LR: {current_lr:.6f} | "
                           f"Avg Train Loss: {avg_train_loss:.6f}")
                if val_data is not None:
                    log_msg += (f" | Val Total Loss: {val_loss_dict['val_total_loss']:.6f} | "
                               f"Val Sup Loss: {val_loss_dict['L_supervised']:.6f} | "
                               f"Val Phys Loss: {val_loss_dict['L_thermo'] + val_loss_dict['L_vorticity']:.6f}")
                print(log_msg)

            # æ”¶æ•›æ£€éªŒï¼ˆå¦‚æœæœ‰éªŒè¯é›†ï¼‰
            if val_data is not None:
                is_converged, converge_msg = self._check_convergence()
                print(f"ğŸ” æ”¶æ•›çŠ¶æ€: {converge_msg}")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if self.train_state['current_epoch'] == self.train_state['best_epoch']:
                    self.save_model("models/best_finetune.pth")
                    self.save_train_state("models/best_finetune_state.pth")
                
                # å¦‚æœæ”¶æ•›ï¼Œæå‰åœæ­¢å¾®è°ƒ
                if is_converged:
                    print(f"ğŸ‰ å…¨å±€å¾®è°ƒæå‰æ”¶æ•›ï¼Œåœæ­¢è®­ç»ƒï¼ˆæ€»è®­ç»ƒè½®æ•°ï¼š{self.train_state['current_epoch']}ï¼‰")
                    break

        print("=== å…¨å±€å¾®è°ƒå®Œæˆ ===")

        # è¿”å›è®­ç»ƒå†å²
        return {
            'train_loss': self.train_state['train_loss_history'],
            'val_loss': self.train_state['val_loss_history'],
            'lr_history': self.train_state['lr_history']
        }

    def _check_convergence(self) -> Tuple[bool, str]:
        """
        æ”¶æ•›æ£€éªŒé€»è¾‘
        è¿”å›ï¼š(æ˜¯å¦æ”¶æ•›, æ”¶æ•›çŠ¶æ€ä¿¡æ¯)
        """
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å°è®­ç»ƒè½®æ•°
        if self.train_state['current_epoch'] < self.config.get('min_epochs', 50):
            return False, f"æœªè¾¾åˆ°æœ€å°è®­ç»ƒè½®æ•°ï¼ˆå½“å‰{self.train_state['current_epoch']}/{self.config.get('min_epochs', 50)}ï¼‰"
        
        # è·å–ç›‘æ§æŒ‡æ ‡çš„å†å²è®°å½•
        if not self.train_state['val_loss_history']:
            return False, "æ— éªŒè¯æŸå¤±è®°å½•ï¼Œæ— æ³•åˆ¤æ–­æ”¶æ•›"
        
        current_metric = self.train_state['val_loss_history'][-1]
        best_metric = self.train_state['best_val_loss']
        
        # åˆ¤æ–­æ˜¯å¦æœ‰æ”¹è¿›
        improvement = best_metric - current_metric
        min_delta = self.config.get('converge_min_delta', 1e-6)
        
        if improvement > min_delta:
            # æœ‰æ˜¾è‘—æ”¹è¿›ï¼šæ›´æ–°æœ€ä½³çŠ¶æ€
            self.train_state['best_val_loss'] = current_metric
            self.train_state['best_epoch'] = self.train_state['current_epoch']
            self.train_state['converge_count'] = 0
            return False, f"æŒ‡æ ‡æ”¹è¿›{improvement:.6f}ï¼Œæ›´æ–°æœ€ä½³çŠ¶æ€ï¼ˆepoch {self.train_state['best_epoch']}ï¼‰"
        else:
            # æ— æ˜¾è‘—æ”¹è¿›ï¼šç´¯è®¡è®¡æ•°
            self.train_state['converge_count'] += 1
            if self.train_state['converge_count'] >= self.config.get('converge_patience', 15):
                # è¾¾åˆ°å®¹å¿ä¸Šé™ï¼Œåˆ¤å®šæ”¶æ•›
                return True, (f"è¿ç»­{self.train_state['converge_count']}ä¸ªepochæ— æ˜¾è‘—æ”¹è¿›ï¼ˆé˜ˆå€¼{min_delta}ï¼‰ï¼Œ"
                              f"è®­ç»ƒæ”¶æ•›ï¼ˆæœ€ä½³epoch: {self.train_state['best_epoch']}, æœ€ä½³éªŒè¯æŸå¤±: {best_metric:.6f}ï¼‰")
            else:
                return False, f"æ— æ˜¾è‘—æ”¹è¿›ï¼Œç´¯è®¡è®¡æ•°{self.train_state['converge_count']}/{self.config.get('converge_patience', 15)}"

    def _evaluate(self, data) -> Dict[str, float]:
        """
        éªŒè¯é›†è¯„ä¼°ï¼ˆæ— æ¢¯åº¦è®¡ç®—ï¼‰
        è¿”å›ï¼šå„æŸå¤±æŒ‡æ ‡å­—å…¸
        """
        self.model.eval()
        data = data.to(self.device)
        region_mask = self._get_region_mask(data)
        
        with torch.no_grad():
            pred, _ = self.model(data.x, data.edge_index)
            
            # åˆ›å»ºä¸´æ—¶æ•°æ®å¯¹è±¡ä»¥åŒ¹é…physics_lossæ¥å£
            temp_data = SimpleData(
                y=data.y,
                pos=data.pos if hasattr(data, 'pos') else None
            )
            
            total_loss, loss_dict = self.physics_loss(
                pred,
                temp_data,
                region_mask
            )
        
        # è¡¥å……æ€»æŸå¤±åˆ°è¿”å›å­—å…¸
        loss_dict['val_total_loss'] = total_loss.item()
        self.model.train()  # æ¢å¤è®­ç»ƒæ¨¡å¼
        return loss_dict

    def save_model(self, path):
        torch.save(self.model.state_dict(), path)
        print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {path}")

    def save_train_state(self, path: str) -> None:
        """ä¿å­˜è®­ç»ƒçŠ¶æ€ï¼ˆç”¨äºä¸­æ–­åæ¢å¤ï¼‰"""
        save_dict = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'train_state': self.train_state,
            'config': self.config
        }
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        torch.save(save_dict, path)
        print(f"âœ… è®­ç»ƒçŠ¶æ€å·²ä¿å­˜è‡³: {path}")

    def load_train_state(self, path: str) -> None:
        """åŠ è½½è®­ç»ƒçŠ¶æ€ï¼ˆä»ä¸­æ–­å¤„æ¢å¤ï¼‰"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.train_state = checkpoint['train_state']
        self.config = checkpoint['config']
        print(f"âœ… è®­ç»ƒçŠ¶æ€å·²åŠ è½½ï¼ˆå½“å‰epoch: {self.train_state['current_epoch']}, æœ€ä½³éªŒè¯æŸå¤±: {self.train_state['best_val_loss']:.6f}ï¼‰")

    def load_model(self, path):
        self.model.load_state_dict(torch.load(path, map_location=self.device))
        print(f"æ¨¡å‹å·²åŠ è½½: {path}")
